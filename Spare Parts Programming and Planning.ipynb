{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bases\n",
    "cod_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Códigos.xlsx') # Lista com PN's e informações\n",
    "lx_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\LX02 8510.XLSX') # Controle do Estoque\n",
    "vor_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Vorplan.xlsx') # Histórico de Planejamento\n",
    "doc_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Faturamento.xlsx') # Histórico de vendas - Considerar coluna valor líq para ABC Geral\n",
    "sp_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\SP99.xlsx') # Custo do Estoque\n",
    "sales_block_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Sales Block.xlsx') # Itens com bloqueio para vendas\n",
    "dispopara_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Dispopara.xlsx') # Informações sobre os itens como bloqueio de planejamento, LT, fornecedores, etc\n",
    "pintados_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Itens Pintados.xlsx') # Verificar itens brutos\n",
    "class_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Classificação.xlsx') # Classificação família dos itens\n",
    "abc_rede_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\ABC rede.xlsx') # Classificação ABC da rede\n",
    "mrp_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Códigos - MRP.xlsx', sheet_name='Geral') # Extração de todos os MRP's\n",
    "va05_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\VA05.xlsx') # Pedidos pendentes de atendimento\n",
    "doc2_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Faturamento.xlsx') # Histórico de vendas\n",
    "\n",
    "# Bases de Máquinas\n",
    "evol241_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Evolution\\\\Maestro Evolution 24_1.xlsx')\n",
    "evol242_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Evolution\\\\Maestro Evolution 24_2.xlsx')\n",
    "evol301_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Evolution\\\\Maestro Evolution 30_1.xlsx')\n",
    "evol302_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Evolution\\\\Maestro Evolution 30_2.xlsx')\n",
    "evol303_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Evolution\\\\Maestro Evolution 30_3.xlsx')\n",
    "evol36_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Evolution\\\\Maestro Evolution 36.xlsx')\n",
    "evol39_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Evolution\\\\Maestro Evolution 39.xlsx')\n",
    "evol40_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Evolution\\\\Maestro Evolution 40.xlsx')\n",
    "evolman_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Evolution\\\\Maestro Evolution_Análise Manual.xlsx')\n",
    "\n",
    "komp14_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Kompass\\\\Maestro Kompass 14.xlsx')\n",
    "komp16_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Kompass\\\\Maestro Kompass 16.xlsx')\n",
    "komp162_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Kompass\\\\Maestro Kompass 16_2.xlsx')\n",
    "komp18_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Kompass\\\\Maestro Kompass 18.xlsx')\n",
    "kompman_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro Kompass\\\\Maestro Kompass_Análise Manual.xlsx')\n",
    "\n",
    "\n",
    "evotl_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\EVO TL\\\\EVO TL.xlsx')\n",
    "\n",
    "evo12cs_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\EVO 12 CS\\\\EVO 12 CS.xlsx')\n",
    "\n",
    "dak8cf_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Dakar CF\\\\Dakar 8 CF.xlsx')\n",
    "dak10cf_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Dakar CF\\\\Dakar 10 CF.xlsx')\n",
    "dakcfman_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Dakar CF\\\\Dakar CF_Análise Manual.xlsx')\n",
    "\n",
    "dak15nt_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Dakar NT\\\\Dakar 15 NT.xlsx')\n",
    "dak18nt_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Dakar NT\\\\Dakar 18 NT.xlsx')\n",
    "dakntman_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Dakar NT\\\\Dakar NT_Análise Manual.xlsx')\n",
    "\n",
    "leebvl_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Leeb VL\\\\Leeb VL.xlsx')\n",
    "\n",
    "sw_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Maestro SW\\\\Maestro SW.xlsx')\n",
    "\n",
    "cul3_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Cultro TC\\\\Cultro 3 TC.xlsx')\n",
    "cul5_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Cultro TC\\\\Cultro 5 TC.xlsx')\n",
    "cul6_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Cultro TC\\\\Cultro 6 TC.xlsx')\n",
    "cul9i_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Cultro TC\\\\Cultro 9 TC – Importado.xlsx')\n",
    "cul9n_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Cultro TC\\\\Cultro 9 TC – Nacional.xlsx')\n",
    "cul12_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Cultro TC\\\\Cultro 12 TC.xlsx')\n",
    "cul18_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Cultro TC\\\\Cultro 18 TC.xlsx')\n",
    "\n",
    "evo8cs_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Evo 8 CS\\\\Evo 8 CS.xlsx')\n",
    "\n",
    "evo24cs_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Evo CS 24.45\\\\Evo CS 24_5.xlsx')\n",
    "\n",
    "jok7_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Joker 7 RT\\\\Joker 7 RT.xlsx')\n",
    "\n",
    "mini_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\MiniDrill\\\\MiniDrill.xlsx')\n",
    "\n",
    "mini_solo_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\MiniDrill SOLO\\\\MiniDrill SOLO.xlsx')\n",
    "\n",
    "part_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Partner 2800 HT\\\\Partner 2800 HT.xlsx')\n",
    "\n",
    "tig_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Tiger MT\\\\Tiger MT.xlsx')\n",
    "\n",
    "mini_flow_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\MiniFlow\\\\MiniFlow_Análise Manual.xlsx')\n",
    "\n",
    "insumos_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Insumos\\\\Insumos_Análise Manual.xlsx')\n",
    "\n",
    "ferramentas_df = pd.read_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Ferramentas\\\\Ferramentas_Análise Manual.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para normalizar os dados de material\n",
    "def normalize_material(df, column_name):\n",
    "    df[column_name] = df[column_name].astype(str).str.strip().str.upper()  # Converte para string, remove espaços e converte para maiúsculas\n",
    "    df[column_name] = df[column_name].str.zfill(11)  # Preenche com zeros à esquerda para garantir 11 dígitos\n",
    "    return df\n",
    "\n",
    "# Normalizando a coluna específica de cada DataFrame\n",
    "cod_df = normalize_material(cod_df, 'PN')\n",
    "lx_df = normalize_material(lx_df, 'Material')\n",
    "sp_df = normalize_material(sp_df, 'Material')\n",
    "doc_df = normalize_material(doc_df, 'Material')\n",
    "vor_df = normalize_material(vor_df, 'A~Material')\n",
    "sales_block_df = normalize_material(sales_block_df, 'Material')\n",
    "dispopara_df = normalize_material(dispopara_df, 'A~Material')\n",
    "pintados_df = normalize_material(pintados_df, 'Material')\n",
    "class_df = normalize_material(class_df, 'Material')\n",
    "abc_rede_df = normalize_material(abc_rede_df, 'MATERIAL')\n",
    "mrp_df = normalize_material(mrp_df, 'Material')\n",
    "va05_df = normalize_material(va05_df, 'A~Material')\n",
    "evol241_df = normalize_material(evol241_df, 'Nº componente')\n",
    "evol242_df = normalize_material(evol242_df, 'Nº componente')\n",
    "evol301_df = normalize_material(evol301_df, 'Nº componente')\n",
    "evol302_df = normalize_material(evol302_df, 'Nº componente')\n",
    "evol303_df = normalize_material(evol303_df, 'Nº componente')\n",
    "evol36_df = normalize_material(evol36_df, 'Nº componente')\n",
    "evol39_df = normalize_material(evol39_df, 'Nº componente')\n",
    "evol40_df = normalize_material(evol40_df, 'Nº componente')\n",
    "evolman_df = normalize_material(evolman_df, 'Nº componente')\n",
    "komp14_df = normalize_material(komp14_df, 'Nº componente')\n",
    "komp16_df = normalize_material(komp16_df, 'Nº componente')\n",
    "komp162_df = normalize_material(komp162_df, 'Nº componente')\n",
    "komp18_df = normalize_material(komp18_df, 'Nº componente')\n",
    "kompman_df = normalize_material(kompman_df, 'Nº componente')\n",
    "evotl_df = normalize_material(evotl_df, 'Nº componente')\n",
    "evo12cs_df = normalize_material(evo12cs_df, 'Nº componente')\n",
    "dak8cf_df = normalize_material(dak8cf_df, 'Nº componente')\n",
    "dak10cf_df = normalize_material(dak10cf_df, 'Nº componente')\n",
    "dakcfman_df = normalize_material(dakcfman_df, 'Nº componente')\n",
    "dak15nt_df = normalize_material(dak15nt_df, 'Nº componente')\n",
    "dak18nt_df = normalize_material(dak18nt_df, 'Nº componente')\n",
    "dakntman_df = normalize_material(dakntman_df, 'Nº componente')\n",
    "leebvl_df = normalize_material(leebvl_df, 'Nº componente')\n",
    "doc2_df = normalize_material(doc2_df, 'Material')\n",
    "sw_df = normalize_material(sw_df, 'Nº componente')\n",
    "cul3_df = normalize_material(cul3_df, 'Nº componente')\n",
    "cul5_df = normalize_material(cul5_df, 'Nº componente')\n",
    "cul6_df = normalize_material(cul6_df, 'Nº componente')\n",
    "cul9i_df = normalize_material(cul9i_df, 'Nº componente')\n",
    "cul9n_df = normalize_material(cul9n_df, 'Nº componente')\n",
    "cul12_df = normalize_material(cul12_df, 'Nº componente')\n",
    "cul18_df = normalize_material(cul18_df, 'Nº componente')\n",
    "evo8cs_df = normalize_material(evo8cs_df, 'Nº componente')\n",
    "evo24cs_df = normalize_material(evo24cs_df, 'Nº componente')\n",
    "jok7_df = normalize_material(jok7_df, 'Nº componente')\n",
    "mini_df = normalize_material(mini_df, 'Nº componente')\n",
    "mini_solo_df = normalize_material(mini_solo_df, 'Nº componente')\n",
    "part_df = normalize_material(part_df, 'Nº componente')\n",
    "tig_df = normalize_material(tig_df, 'Nº componente')\n",
    "mini_flow_df = normalize_material(mini_flow_df, 'Nº componente')\n",
    "insumos_df = normalize_material(insumos_df, 'Nº componente')\n",
    "ferramentas_df = normalize_material(ferramentas_df, 'Nº componente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação da base - unidades de medida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([evol241_df, evol242_df, evol301_df, evol302_df, evol36_df, evol39_df, evol40_df, komp14_df, komp16_df, komp18_df, evotl_df, evo12cs_df, dak8cf_df, dak10cf_df, dak15nt_df, dak18nt_df, leebvl_df, sw_df, cul3_df, cul5_df, cul6_df, cul9i_df, cul9n_df, cul12_df, cul18_df, evo8cs_df, evo24cs_df, jok7_df, mini_df, mini_solo_df, part_df, tig_df], axis= 0)\n",
    "concat_df = concat_df[['Nº componente', 'Unid.med.componente']]\n",
    "concat_df = concat_df.rename(columns= {'Unid.med.componente': 'Unidade de Medida'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_2_df = concat_df.groupby('Nº componente')['Unidade de Medida'].nunique().reset_index()\n",
    "concat_2_df.sort_values('Unidade de Medida', ascending= False, inplace= True) \n",
    "concat_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = concat_df.drop_duplicates(subset= 'Nº componente', keep= 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planilha base de códigos ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx_df_2 = lx_df\n",
    "vor_df_2 = vor_df\n",
    "doc_df_2 = doc_df\n",
    "va05_df_2 = va05_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas com informações não condinzentes com os dados de vendas\n",
    "doc_df_2 = doc_df_2.drop(doc_df_2[doc_df_2['TpDocVend.'] != 'Z000'].index)\n",
    "doc_df_2 = doc_df_2.drop(doc_df_2[doc_df_2['G~Ctg.NF'] != '1N'].index)\n",
    "doc_df_2 = doc_df_2.drop(doc_df_2[doc_df_2['G~Estornado'] == 'X'].index)\n",
    "doc_df_2 = doc_df_2[doc_df_2['Material'] != '00099000100'] # scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas com informações não condinzentes com os dados de vendas\n",
    "va05_df_2 = va05_df_2.drop(va05_df_2[va05_df_2['A~TpDocVnds.'] != 'Z000'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando as colunas para posterior união das bases\n",
    "lx_df_2.rename(columns={'Material': 'PN', 'Texto breve material': 'Descrição', 'UM básica': 'Unidade'}, inplace=True)\n",
    "lx_df_2 = lx_df_2[['PN', 'Descrição', 'Unidade']]\n",
    "\n",
    "vor_df_2.rename(columns={'A~Material': 'PN', 'A~Material.1': 'Descrição', 'B~Unidade': 'Unidade'}, inplace=True)\n",
    "vor_df_2 = vor_df_2[['PN', 'Descrição', 'Unidade']]\n",
    "\n",
    "doc_df_2.rename(columns={'Material': 'PN', 'B~Denominaç.': 'Descrição', 'UV': 'Unidade'}, inplace=True)\n",
    "doc_df_2 = doc_df_2[['PN', 'Descrição', 'Unidade']]\n",
    "\n",
    "va05_df_2.rename(columns={'A~Material': 'PN', 'A~Material.1': 'Descrição', 'A~Unidade': 'Unidade'}, inplace=True)\n",
    "va05_df_2 = va05_df_2[['PN', 'Descrição', 'Unidade']]\n",
    "\n",
    "doc_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unindo as bases para garantir que estamos analisando todos os códigos\n",
    "cod_df = pd.concat([cod_df, lx_df_2, vor_df_2, doc_df_2, va05_df_2])\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando e removendo diplicadas\n",
    "cod_df = cod_df.drop_duplicates(subset='PN', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo código do scrap\n",
    "cod_df = cod_df[cod_df['PN'] != '00099000100'] # scrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LX02 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando planilha de estoque - Retirar itens em seperação para cliente: \"916\"\n",
    "lx_df = lx_df.drop(lx_df[lx_df['Tipo de depósito'] == 916].index)\n",
    "\n",
    "# Agrupando a quantidade em estoque por material\n",
    "lx_df = lx_df.groupby('PN')['Estoque disponível'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SP99 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo valores em branco da coluna 'Material'\n",
    "sp_df = sp_df.drop(sp_df[sp_df['Material'].isin(['nan'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserindo coluna \"Valor unitário\" na SP99\n",
    "sp_df['Valor unitário'] = np.where(sp_df['Preço interno periódico'] == 0, \n",
    "                                   sp_df['Preço-padrão'] / sp_df['Unidade de preço'], \n",
    "                                   sp_df['Preço interno periódico'] / sp_df['Unidade de preço'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando e removendo diplicadas\n",
    "sp_df.sort_values(by='Estoque total', ascending=False, inplace=True) # coluna Estoque total do maior para o menor)\n",
    "sp_df = sp_df.drop_duplicates(subset='Material', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DocFlow - Faturamento ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas com informações não condinzentes com os dados de vendas\n",
    "doc_df = doc_df.drop(doc_df[doc_df['TpDocVend.'] != 'Z000'].index)\n",
    "doc_df = doc_df.drop(doc_df[doc_df['G~Ctg.NF'] != '1N'].index)\n",
    "doc_df = doc_df.drop(doc_df[doc_df['G~Estornado'] == 'X'].index)\n",
    "doc_df = doc_df[doc_df['Material'] != '00099000100'] # scrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o valor líquido do código no pedido \n",
    "doc_df['Valor unitário'] = doc_df['B~Val.líq.'] / doc_df['D~Qtd.neces.']\n",
    "doc_df['Valor unitário do pedido'] = doc_df['Valor unitário'] * doc_df['Qtd.faturd']\n",
    "\n",
    "# Criando coluna com o Valor final de NF\n",
    "def Valor_unitário_final(row):\n",
    "    if row['B~Moeda'] == 'BRL':\n",
    "        return row['Valor unitário do pedido'] \n",
    "    else:\n",
    "        return row['E~Total']  \n",
    "\n",
    "# Aplicando a função para criar a nova coluna\n",
    "doc_df['Valor_unitário_final'] = doc_df.apply(Valor_unitário_final, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por 'Material' e somar 'Valor_unitário_final' para cada material\n",
    "df_grouped = doc_df.groupby('Material')['Valor_unitário_final'].sum().reset_index()\n",
    "\n",
    "# Ordenar os materiais pelo valor faturado em ordem decrescente\n",
    "df_grouped = df_grouped.sort_values(by='Valor_unitário_final', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Calcular a porcentagem acumulada do faturamento\n",
    "df_grouped['Porcentagem Acumulada'] = df_grouped['Valor_unitário_final'].cumsum() / df_grouped['Valor_unitário_final'].sum()\n",
    "\n",
    "# Classificar os itens como A, B ou C \n",
    "'''A: responsáveis por 70% do faturamento.\n",
    "B: responsáveis pelos próximos 20% do faturamento.\n",
    "C: responsáveis pelos últimos 10% do faturamento.'''\n",
    "\n",
    "\n",
    "def classificar_item(row):\n",
    "    if row['Porcentagem Acumulada'] <= 0.7:\n",
    "        return 'A'\n",
    "    elif row['Porcentagem Acumulada'] <= 0.9:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "\n",
    "df_grouped['ABC Geral'] = df_grouped.apply(classificar_item, axis=1)\n",
    "\n",
    "\n",
    "# Exibir o dataframe resultante\n",
    "#df_grouped.to_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\ABC.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por 'Material' e somar 'Qtd.faturd' para cada material\n",
    "df_grouped_2 = doc_df.groupby('Material')['Qtd.faturd'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Block ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo Duplicadas\n",
    "sales_block_df = sales_block_df.drop_duplicates(subset='Material', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispopara ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo Duplicadas\n",
    "dispopara_df = dispopara_df.drop_duplicates(subset='A~Material', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o lead time de cada item\n",
    "dispopara_df['Lead Time'] = dispopara_df['B~Mrg.seg.'] + dispopara_df['B~TmpoProcEM'] + dispopara_df['D~PrzEntPrev']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a coluna 'LT Final' com a ondição especificada\n",
    "dispopara_df['Final LT'] = np.where(dispopara_df['Lead Time'] == 83, 90, dispopara_df['Lead Time'])\n",
    "\n",
    "# Criando a coluna com a data prevista\n",
    "dispopara_df['LT Data'] = (pd.to_datetime(datetime.now()) + pd.to_timedelta(dispopara_df['Final LT'], unit='D')).dt.date\n",
    "\n",
    "dispopara_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itens Pintados ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo Duplicadas\n",
    "pintados_df = pintados_df.drop_duplicates(subset='Material', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação dos códigos ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo Duplicadas\n",
    "class_df = class_df.drop_duplicates(subset='Material', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABC Clientes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrigindo informações na coluna 'MATERIAL'\n",
    "abc_rede_df['MATERIAL'] = abc_rede_df['MATERIAL'].str.replace('HR-', '000', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando DataFrame\n",
    "abc_rede_df.sort_values(by='CLASSIFICAÇÃO', ascending=True, inplace=True) \n",
    "\n",
    "# Removendo Duplicadas\n",
    "abc_rede_df = abc_rede_df.drop_duplicates(subset='MATERIAL', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorplan ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por 'Material' e somar 'B~Qtd.plan.' para cada material\n",
    "vor_df = vor_df.groupby('PN')['B~Qtd.plan.'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VA05 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas com informações não condinzentes com os dados de vendas\n",
    "va05_df = va05_df.drop(va05_df[va05_df['A~TpDocVnds.'] != 'Z000'].index)\n",
    "va05_df = va05_df[va05_df['A~Material'] != '00099000100'] # scrap\n",
    "\n",
    "# Agrupar por 'Material' e somar 'B~Qtd.plan.' para cada material\n",
    "va05_df = va05_df.groupby('A~Material')['A~Pendente'].sum().reset_index()\n",
    "\n",
    "#va05_df.to_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\VA05_.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupando as informações para posterior análises #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame base será o cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + lx_df\n",
    "cod_df = cod_df.merge(lx_df[['PN', 'Estoque disponível']], on='PN', how='left')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['Estoque disponível'] = cod_df['Estoque disponível'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + df_grouped - ABC geral\n",
    "cod_df = cod_df.merge(df_grouped[['Material','ABC Geral']], left_on= 'PN', right_on='Material', how= 'left')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['ABC Geral'] = cod_df['ABC Geral'].fillna('C')\n",
    "\n",
    "# Removendo coluna desnecessária\n",
    "cod_df = cod_df.drop(columns='Material')\n",
    "\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + class_df\n",
    "cod_df = cod_df.merge(class_df[['Material', 'Descrição Família']], left_on= 'PN', right_on='Material', how= 'left')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['Descrição Família'] = cod_df['Descrição Família'].fillna('-')\n",
    "\n",
    "# Removendo coluna desnecessária\n",
    "cod_df = cod_df.drop(columns='Material')\n",
    "\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + class_df\n",
    "cod_df = cod_df.merge(abc_rede_df[['MATERIAL', 'CLASSIFICAÇÃO']], left_on= 'PN', right_on='MATERIAL', how= 'left')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['CLASSIFICAÇÃO'] = cod_df['CLASSIFICAÇÃO'].fillna('-')\n",
    "\n",
    "# Removendo coluna desnecessária\n",
    "cod_df = cod_df.drop(columns='MATERIAL')\n",
    "\n",
    "# Renomeando Coluna\n",
    "cod_df.rename(columns={'CLASSIFICAÇÃO': 'ABC Rede'}, inplace = True)\n",
    "\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + pintados_df\n",
    "cod_df = cod_df.merge(pintados_df[['Material', 'Unpainted Part']], left_on= 'PN', right_on='Material', how= 'left')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['Unpainted Part'] = cod_df['Unpainted Part'].fillna('-')\n",
    "\n",
    "# Removendo coluna desnecessária\n",
    "cod_df = cod_df.drop(columns='Material')\n",
    "\n",
    "# Renomeando Coluna\n",
    "cod_df.rename(columns={'Unpainted Part': 'Código dos Itens Brutos'}, inplace = True)\n",
    "\n",
    "# Criando coluna com a análise\n",
    "cod_df['Análise dos itens Brutos'] = cod_df.apply(lambda row: 'Item Bruto' if row['Código dos Itens Brutos'] == row['PN'] else 'OK', axis=1)\n",
    "\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + sales_block_df\n",
    "cod_df = cod_df.merge(sales_block_df[['Material', 'Status.1']], left_on= 'PN', right_on='Material', how= 'left')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['Status.1'] = cod_df['Status.1'].fillna('-')\n",
    "\n",
    "# Removendo coluna desnecessária\n",
    "cod_df = cod_df.drop(columns='Material')\n",
    "\n",
    "# Renomeando Coluna\n",
    "cod_df.rename(columns={'Status.1': 'Status Block'}, inplace = True)\n",
    "\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + dispopara_df\n",
    "cod_df = cod_df.merge(dispopara_df[['A~Material', 'F~StatusMat..1', 'Final LT', 'LT Data', 'B~Planj.MRP.1', 'E~Nome', 'B~Pt.reabast', 'B~TamMínLote', 'B~Val.arred.', 'F~Grp.merc..1']], left_on= 'PN', right_on='A~Material', how= 'left')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['F~StatusMat..1'] = cod_df['F~StatusMat..1'].fillna('-')\n",
    "cod_df['Final LT'] = cod_df['Final LT'].fillna('-')\n",
    "cod_df['B~Planj.MRP.1'] = cod_df['B~Planj.MRP.1'].fillna('-')\n",
    "cod_df['E~Nome'] = cod_df['E~Nome'].fillna('-')\n",
    "\n",
    "# Removendo coluna desnecessária\n",
    "cod_df = cod_df.drop(columns='A~Material')\n",
    "\n",
    "# Renomeando Coluna\n",
    "cod_df.rename(columns={'F~StatusMat..1': 'Plan Block', 'B~Planj.MRP.1': 'Planejador MRP (Dispopara)', 'E~Nome': 'Fornecedor', 'B~Pt.reabast': 'Ponto de Reabastecimento', 'B~TamMínLote': 'Tam. Mín. Lote', 'B~Val.arred.': 'Valor Arredondamento', 'F~Grp.merc..1': 'Família Compras'}, inplace = True)\n",
    "\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + mrp_df\n",
    "cod_df = cod_df.merge(mrp_df[['Material', 'Planejador MRP']], left_on= 'PN', right_on='Material', how= 'left')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['Planejador MRP'] = cod_df['Planejador MRP'].fillna('-')\n",
    "\n",
    "# Removendo coluna desnecessária\n",
    "cod_df = cod_df.drop(columns='Material')\n",
    "\n",
    "# Renomeando Coluna\n",
    "cod_df.rename(columns={'Planejador MRP': 'Planejador MRP (MD06)'}, inplace = True)\n",
    "\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + vor_df\n",
    "cod_df = cod_df.merge(vor_df[['PN', 'B~Qtd.plan.']], on='PN', how= 'left')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['B~Qtd.plan.'] = cod_df['B~Qtd.plan.'].fillna(0)\n",
    "\n",
    "# Renomeando Coluna\n",
    "cod_df.rename(columns={'B~Qtd.plan.': 'Vorplan'}, inplace = True)\n",
    "\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + sp_df\n",
    "cod_df = cod_df.merge(sp_df[['Material', 'Valor unitário']], left_on= 'PN', right_on='Material', how= 'left')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['Valor unitário'] = cod_df['Valor unitário'].fillna(0)\n",
    "\n",
    "# Removendo coluna desnecessária\n",
    "cod_df = cod_df.drop(columns='Material')\n",
    "\n",
    "# Renomeando Coluna\n",
    "cod_df.rename(columns={'Valor unitário': 'Valor unitário SP99'}, inplace = True)\n",
    "\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + va05_df\n",
    "cod_df = cod_df.merge(va05_df[['A~Material', 'A~Pendente']], left_on= 'PN', right_on='A~Material', how= 'left')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['A~Pendente'] = cod_df['A~Pendente'].fillna(0)\n",
    "\n",
    "# Removendo coluna desnecessária\n",
    "cod_df = cod_df.drop(columns='A~Material')\n",
    "\n",
    "# Renomeando Coluna\n",
    "cod_df.rename(columns={'A~Pendente': 'VA05'}, inplace = True)\n",
    "\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análises #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custo de estoque\n",
    "cod_df['Custo Estoque'] = cod_df['Estoque disponível'] * cod_df['Valor unitário SP99']\n",
    "cod_df['Custo Estoque'] = round((cod_df['Custo Estoque']),2)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histórico de vendas 1M ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna de data para o tipo datetime\n",
    "doc_df['F~Dt.fatur.'] = pd.to_datetime(doc_df['F~Dt.fatur.'], format='%d/%m/%Y')\n",
    "\n",
    "# Definir a data de hoje\n",
    "data_hoje = pd.Timestamp.now()  \n",
    "\n",
    "# Extrair o último mês e ano\n",
    "mes_anterior = data_hoje.month - 1 if data_hoje.month > 1 else 12\n",
    "ano_anterior = data_hoje.year if data_hoje.month > 1 else data_hoje.year - 1\n",
    "\n",
    "# Novo df\n",
    "df_1m = doc_df\n",
    "# Filtrar as vendas do mês anterior\n",
    "df_mes_anterior = df_1m[(df_1m['F~Dt.fatur.'].dt.month == mes_anterior) & \n",
    "                         (df_1m['F~Dt.fatur.'].dt.year == ano_anterior)]\n",
    "\n",
    "# Agora, para cada linha do DataFrame original, fazer a média das quantidades faturadas do último mês para o mesmo Material\n",
    "# Criar uma coluna nova com o somatório\n",
    "df_1m['Soma_ultimo_mes'] = df_1m['Material'].apply(lambda x: df_mes_anterior[df_mes_anterior['Material'] == x]['Qtd.faturd'].sum())\n",
    "#df_1m = df_1m.groupby('Material')['Soma_ultimo_mes'].mean().reset_index()\n",
    "\n",
    "# Arredondar valores para cima \n",
    "df_1m['Soma_ultimo_mes'] = np.ceil(df_1m['Soma_ultimo_mes'])\n",
    "\n",
    "#Remover Duplicadas\n",
    "df_1m = df_1m.drop_duplicates(subset='Material', keep='first')\n",
    "\n",
    "#Manter apenas colunas necessárias\n",
    "df_1m = df_1m[['Material', 'Soma_ultimo_mes']]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "df_1m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histórico de vendas 12M ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a data de hoje para o início do mês atual\n",
    "data_hoje = pd.Timestamp.now().normalize().replace(day=1)\n",
    "\n",
    "# Definir a data de 12 meses atrás\n",
    "data_12_meses_atras = data_hoje - pd.DateOffset(months=12)\n",
    "\n",
    "# Novo df\n",
    "df_12m = doc_df\n",
    "\n",
    "# Filtrar as vendas dos últimos 12 meses (deve ser do mês anterior ao atual até 12 meses atrás)\n",
    "df_ultimos_12_meses = df_12m[(df_12m['F~Dt.fatur.'] >= data_12_meses_atras) & \n",
    "                             (df_12m['F~Dt.fatur.'] < data_hoje)]\n",
    "\n",
    "# Agora, para cada linha do DataFrame original, calcular a soma e a média das quantidades faturadas nos últimos 12 meses para o mesmo Material\n",
    "df_12m['Soma_ultimos_12_meses'] = df_12m['Material'].apply(lambda x: df_ultimos_12_meses[df_ultimos_12_meses['Material'] == x]['Qtd.faturd'].sum())\n",
    "df_12m['Média_ultimos_12_meses'] = df_12m['Soma_ultimos_12_meses'] / 12\n",
    "\n",
    "# Arredondar valores para cima \n",
    "df_12m['Média_ultimos_12_meses'] = np.ceil(df_12m['Média_ultimos_12_meses'])\n",
    "\n",
    "# Remover duplicadas\n",
    "df_12m = df_12m.drop_duplicates(subset='Material', keep='first')\n",
    "\n",
    "# Manter apenas colunas necessárias\n",
    "df_12m = df_12m[['Material', 'Média_ultimos_12_meses']]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "df_12m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histórico de vendas 24M ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a data de hoje para o início do mês atual\n",
    "data_hoje = pd.Timestamp.now().normalize().replace(day=1)\n",
    "\n",
    "# Definir a data de 12 meses atrás\n",
    "data_24_meses_atras = data_hoje - pd.DateOffset(months=24)\n",
    "\n",
    "# Novo df\n",
    "df_24m = doc_df\n",
    "\n",
    "# Filtrar as vendas dos últimos 24 meses\n",
    "df_ultimos_24_meses = df_24m[(df_24m['F~Dt.fatur.'] >= data_24_meses_atras) & \n",
    "                             (df_24m['F~Dt.fatur.'] < data_hoje)]\n",
    "\n",
    "# Agora, para cada linha do DataFrame original, fazer a média das quantidades faturadas nos últimos 24 meses para o mesmo Material\n",
    "df_24m['Soma_ultimos_24_meses'] = df_24m['Material'].apply(lambda x: df_ultimos_24_meses[df_ultimos_24_meses['Material'] == x]['Qtd.faturd'].sum())\n",
    "df_24m['Média_ultimos_24_meses'] = df_24m['Soma_ultimos_24_meses'] / 24\n",
    "\n",
    "# Arredondar valores para cima \n",
    "df_24m['Média_ultimos_24_meses'] = np.ceil(df_24m['Média_ultimos_24_meses'])\n",
    "\n",
    "# Remover duplicadas\n",
    "df_24m = df_24m.drop_duplicates(subset='Material', keep='first')\n",
    "\n",
    "# Manter apenas colunas necessárias\n",
    "df_24m = df_24m[['Material', 'Média_ultimos_24_meses']]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "df_24m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histórico de vendas 36M ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a data de hoje para o início do mês atual\n",
    "data_hoje = pd.Timestamp.now().normalize().replace(day=1)\n",
    "\n",
    "# Definir a data de 36 meses atrás\n",
    "data_36_meses_atras = data_hoje - pd.DateOffset(months=36)\n",
    "\n",
    "# Novo df\n",
    "df_36m = doc_df\n",
    "\n",
    "# Filtrar as vendas dos últimos 36 meses\n",
    "df_ultimos_36_meses = df_36m[(df_36m['F~Dt.fatur.'] >= data_36_meses_atras) & \n",
    "                             (df_36m['F~Dt.fatur.'] < data_hoje)]\n",
    "\n",
    "# Agora, para cada linha do DataFrame original, fazer a média das quantidades faturadas nos últimos 36 meses para o mesmo Material\n",
    "df_36m['Soma_ultimos_36_meses'] = df_36m['Material'].apply(lambda x: df_ultimos_36_meses[df_ultimos_36_meses['Material'] == x]['Qtd.faturd'].sum())\n",
    "df_36m['Média_ultimos_36_meses'] = df_36m['Soma_ultimos_36_meses'] / 36\n",
    "\n",
    "# Arredondar valores para cima \n",
    "df_36m['Média_ultimos_36_meses'] = np.ceil(df_36m['Média_ultimos_36_meses'])\n",
    "\n",
    "# Remover duplicadas\n",
    "df_36m = df_36m.drop_duplicates(subset='Material', keep='first')\n",
    "\n",
    "# Manter apenas colunas necessárias\n",
    "df_36m = df_36m[['Material', 'Média_ultimos_36_meses']]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "df_36m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unindo informações novamente ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cod_df + doc_df\n",
    "cod_df = cod_df.merge(df_1m[['Material', 'Soma_ultimo_mes']], left_on= 'PN', right_on='Material', how= 'left')\n",
    "cod_df = cod_df.drop(columns='Material')\n",
    "cod_df = cod_df.merge(df_12m[['Material', 'Média_ultimos_12_meses']], left_on= 'PN', right_on='Material', how= 'left')\n",
    "cod_df = cod_df.drop(columns='Material')\n",
    "cod_df = cod_df.merge(df_24m[['Material', 'Média_ultimos_24_meses']], left_on= 'PN', right_on='Material', how= 'left')\n",
    "cod_df = cod_df.drop(columns='Material')\n",
    "cod_df = cod_df.merge(df_36m[['Material', 'Média_ultimos_36_meses']], left_on= 'PN', right_on='Material', how= 'left')\n",
    "cod_df = cod_df.drop(columns='Material')\n",
    "\n",
    "# Substituir valores ausentes com um valor fixo\n",
    "cod_df['Soma_ultimo_mes'] = cod_df['Soma_ultimo_mes'].fillna(0)\n",
    "cod_df['Média_ultimos_12_meses'] = cod_df['Média_ultimos_12_meses'].fillna(0)\n",
    "cod_df['Média_ultimos_24_meses'] = cod_df['Média_ultimos_24_meses'].fillna(0)\n",
    "cod_df['Média_ultimos_36_meses'] = cod_df['Média_ultimos_36_meses'].fillna(0)\n",
    "\n",
    "# Renomeando Coluna\n",
    "cod_df.rename(columns={'Soma_ultimo_mes': '1M', 'Média_ultimos_12_meses': '12M', 'Média_ultimos_24_meses': '24M', 'Média_ultimos_36_meses': '36M'}, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cobertura de Estoque ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df['Planejado (Trânsito)'] = cod_df.apply(lambda row: max(0, row['Vorplan'] - row['Estoque disponível']), axis=1)\n",
    "\n",
    "# Evitar divisão por zero\n",
    "cod_df['Cobertura de Estoque'] = cod_df.apply(lambda row: max(0, row['Estoque disponível'] / row['24M']) if row['24M'] != 0 else 0, axis=1)\n",
    "cod_df['Cobertura Virtual'] = cod_df.apply(lambda row: max(0, row['Planejado (Trânsito)'] / row['24M']) if row['24M'] != 0 else 0, axis=1)\n",
    "cod_df['Total'] = cod_df['Cobertura de Estoque'] + cod_df['Cobertura Virtual']\n",
    "\n",
    "# Arredondar valores para o valor mais próximo\n",
    "cod_df['Cobertura de Estoque'] = round(cod_df['Cobertura de Estoque'],0)\n",
    "cod_df['Cobertura Virtual'] = round(cod_df['Cobertura Virtual'],0)\n",
    "cod_df['Total'] = round(cod_df['Total'],0)\n",
    "\n",
    "# Cobertura para ABC qualificado\n",
    "cod_df['Sugestão Cobertura ABC'] = cod_df['ABC qualificado '].map({\n",
    "    'A': 3,\n",
    "    'B': 2,\n",
    "    'C': 1,\n",
    "    'D': 1\n",
    "}).fillna(1)  # Preencher NaN com 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sugestão Planejamento ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df['Sugestão'] = cod_df.apply(lambda row: np.ceil(\n",
    "    0 if (row['VA05'] + (row['24M'] * row['Sugestão Cobertura ABC']) - (row['Estoque disponível'] + row['Planejado (Trânsito)'])) < 0 \n",
    "    else (row['VA05'] + (row['24M'] * row['Sugestão Cobertura ABC']) - (row['Estoque disponível'] + row['Planejado (Trânsito)']))\n",
    "), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nova_ordem = ['PN', 'Descrição', 'Unidade', 'Estoque disponível', 'Valor unitário SP99', 'Custo Estoque', 'ABC Geral', 'Descrição Família', 'Família Compras', 'ABC qualificado ', 'ABC Rede', 'Código dos Itens Brutos', 'Análise dos itens Brutos', 'Status Block', 'Plan Block', '1M', '12M', '24M', '36M', 'Cobertura de Estoque', 'Cobertura Virtual', 'Total', 'Vorplan', 'Planejado (Trânsito)', 'Final LT', 'Planejador MRP (Dispopara)', 'Planejador MRP (MD06)', 'VA05', 'Sugestão Cobertura ABC', 'Sugestão', 'LT Data', 'Ponto de Reabastecimento', 'Tam. Mín. Lote', 'Valor Arredondamento', 'Observações', 'Fornecedor', 'Item Substituto', 'Classificação E ou F Brasil']\n",
    "cod_df = cod_df[nova_ordem]\n",
    "cod_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantidade Por Máquinas ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maestro Evolution\n",
    "evol241_df = evol241_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Evolution'})\n",
    "evol242_df = evol242_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Evolution'})\n",
    "evol301_df = evol301_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Evolution'})\n",
    "evol302_df = evol302_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Evolution'})\n",
    "evol303_df = evol303_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Evolution'})\n",
    "evol36_df = evol36_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Evolution'})\n",
    "evol39_df = evol39_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Evolution'})\n",
    "evol40_df = evol40_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Evolution'})\n",
    "evolman_df = evolman_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Evolution'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evol241_df = evol241_df.groupby('Nº componente')['Qtd Evolution'].sum().reset_index()\n",
    "evol242_df = evol242_df.groupby('Nº componente')['Qtd Evolution'].sum().reset_index()\n",
    "evol301_df = evol301_df.groupby('Nº componente')['Qtd Evolution'].sum().reset_index()\n",
    "evol302_df = evol302_df.groupby('Nº componente')['Qtd Evolution'].sum().reset_index()\n",
    "evol303_df = evol303_df.groupby('Nº componente')['Qtd Evolution'].sum().reset_index()\n",
    "evol36_df = evol36_df.groupby('Nº componente')['Qtd Evolution'].sum().reset_index()\n",
    "evol39_df = evol39_df.groupby('Nº componente')['Qtd Evolution'].sum().reset_index()\n",
    "evol40_df = evol40_df.groupby('Nº componente')['Qtd Evolution'].sum().reset_index()\n",
    "evolman_df = evolman_df.groupby('Nº componente')['Qtd Evolution'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evol_df = pd.concat([evol241_df, evol242_df, evol301_df, evol302_df, evol303_df, evol36_df, evol39_df, evol40_df, evolman_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evol_df.sort_values('Qtd Evolution', ascending= False, inplace = True)\n",
    "evol_df = evol_df.drop_duplicates(subset='Nº componente', keep='first')\n",
    "evol_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(evol_df[['Nº componente', 'Qtd Evolution']],left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns='Nº componente')\n",
    "cod_df['Qtd Evolution'] = cod_df['Qtd Evolution'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maestro Kompass\n",
    "komp14_df = komp14_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Kompass'})\n",
    "komp16_df = komp16_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Kompass'})\n",
    "komp162_df = komp162_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Kompass'})\n",
    "komp18_df = komp18_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Kompass'})\n",
    "kompman_df = kompman_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Kompass'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "komp14_df = komp14_df.groupby('Nº componente')['Qtd Kompass'].sum().reset_index()\n",
    "komp16_df = komp16_df.groupby('Nº componente')['Qtd Kompass'].sum().reset_index()\n",
    "komp162_df = komp162_df.groupby('Nº componente')['Qtd Kompass'].sum().reset_index()\n",
    "komp18_df = komp18_df.groupby('Nº componente')['Qtd Kompass'].sum().reset_index()\n",
    "kompman_df = kompman_df.groupby('Nº componente')['Qtd Kompass'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "komp_df = pd.concat([komp14_df, komp16_df, komp162_df, komp18_df, kompman_df], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "komp_df.sort_values('Qtd Kompass', ascending= False, inplace= True)\n",
    "komp_df = komp_df.drop_duplicates(subset= 'Nº componente', keep='first')\n",
    "komp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(komp_df[['Nº componente', 'Qtd Kompass']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns='Nº componente')\n",
    "cod_df['Qtd Kompass'] = cod_df['Qtd Kompass'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVO TL\n",
    "evotl_df = evotl_df.rename(columns={'Qtd.componente (UMC)': 'Qtd EVO TL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evotl_df = evotl_df.groupby('Nº componente')['Qtd EVO TL'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(evotl_df[['Nº componente', 'Qtd EVO TL']], left_on='PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns='Nº componente')\n",
    "cod_df['Qtd EVO TL'] = cod_df['Qtd EVO TL'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVO 12 CS\n",
    "evo12cs_df = evo12cs_df.rename(columns={'Qtd.componente (UMC)': 'Qtd EVO 12 CS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo12cs_df = evo12cs_df.groupby('Nº componente')['Qtd EVO 12 CS'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(evo12cs_df[['Nº componente', 'Qtd EVO 12 CS']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd EVO 12 CS'] = cod_df['Qtd EVO 12 CS'].fillna(0)\n",
    "cod_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dakar CF\n",
    "dak8cf_df = dak8cf_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Dakar CF'})\n",
    "dak10cf_df = dak10cf_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Dakar CF'})\n",
    "dakcfman_df = dakcfman_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Dakar CF'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dak8cf_df = dak8cf_df.groupby('Nº componente')['Qtd Dakar CF'].sum().reset_index()\n",
    "dak10cf_df = dak10cf_df.groupby('Nº componente')['Qtd Dakar CF'].sum().reset_index()\n",
    "dakcfman_df = dakcfman_df.groupby('Nº componente')['Qtd Dakar CF'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dakcf_df = pd.concat([dak8cf_df, dak10cf_df, dakcfman_df], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dakcf_df.sort_values('Qtd Dakar CF', ascending= False, inplace= True)\n",
    "dakcf_df = dakcf_df.drop_duplicates(subset='Nº componente', keep='first')\n",
    "dakcf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(dakcf_df[['Nº componente', 'Qtd Dakar CF']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Dakar CF'] = cod_df['Qtd Dakar CF'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dakar NT\n",
    "dak15nt_df = dak15nt_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Dakar NT'})\n",
    "dak18nt_df = dak18nt_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Dakar NT'})\n",
    "dakntman_df = dakntman_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Dakar NT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dak15nt_df = dak15nt_df.groupby('Nº componente')['Qtd Dakar NT'].sum().reset_index()\n",
    "dak18nt_df = dak18nt_df.groupby('Nº componente')['Qtd Dakar NT'].sum().reset_index()\n",
    "dakntman_df = dakntman_df.groupby('Nº componente')['Qtd Dakar NT'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daknt_df = pd.concat([dak15nt_df, dak18nt_df, dakntman_df], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daknt_df.sort_values('Qtd Dakar NT', ascending= False, inplace= True)\n",
    "daknt_df = daknt_df.drop_duplicates(subset= 'Nº componente', keep= 'first')\n",
    "daknt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(daknt_df[['Nº componente', 'Qtd Dakar NT']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Dakar NT'] = cod_df['Qtd Dakar NT'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leeb VL\n",
    "leebvl_df = leebvl_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Leeb VL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leebvl_df = leebvl_df.groupby('Nº componente')['Qtd Leeb VL'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(leebvl_df[['Nº componente', 'Qtd Leeb VL']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Leeb VL'] = cod_df['Qtd Leeb VL'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maestro SW\n",
    "sw_df = sw_df.rename(columns= {'Qtd.componente (UMC)': 'Qtd Maestro SW'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_df = sw_df.groupby('Nº componente')['Qtd Maestro SW'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(sw_df[['Nº componente', 'Qtd Maestro SW']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Maestro SW'] = cod_df['Qtd Maestro SW'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cultro TC\n",
    "cul3_df = cul3_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Cultro TC'})\n",
    "cul5_df = cul5_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Cultro TC'})\n",
    "cul6_df = cul6_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Cultro TC'})\n",
    "cul9i_df = cul9i_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Cultro TC'})\n",
    "cul9n_df = cul9n_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Cultro TC'})\n",
    "cul12_df = cul12_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Cultro TC'})\n",
    "cul18_df = cul18_df.rename(columns={'Qtd.componente (UMC)': 'Qtd Cultro TC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cul3_df = cul3_df.groupby('Nº componente')['Qtd Cultro TC'].sum().reset_index()\n",
    "cul5_df = cul5_df.groupby('Nº componente')['Qtd Cultro TC'].sum().reset_index()\n",
    "cul6_df = cul6_df.groupby('Nº componente')['Qtd Cultro TC'].sum().reset_index()\n",
    "cul9i_df = cul9i_df.groupby('Nº componente')['Qtd Cultro TC'].sum().reset_index()\n",
    "cul9n_df = cul9n_df.groupby('Nº componente')['Qtd Cultro TC'].sum().reset_index()\n",
    "cul12_df = cul12_df.groupby('Nº componente')['Qtd Cultro TC'].sum().reset_index()\n",
    "cul18_df = cul18_df.groupby('Nº componente')['Qtd Cultro TC'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cul_df = pd.concat([cul3_df, cul5_df, cul6_df, cul9i_df, cul9n_df, cul12_df, cul18_df], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cul_df.sort_values('Qtd Cultro TC', ascending= False, inplace= True)\n",
    "cul_df = cul_df.drop_duplicates(subset= 'Nº componente', keep= 'first')\n",
    "cul_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(cul_df[['Nº componente', 'Qtd Cultro TC']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Cultro TC'] = cod_df['Qtd Cultro TC'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evo 8 CS\n",
    "evo8cs_df = evo8cs_df.rename(columns= {'Qtd.componente (UMC)': 'Qtd Evo 8 CS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo8cs_df = evo8cs_df.groupby('Nº componente')['Qtd Evo 8 CS'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(evo8cs_df[['Nº componente', 'Qtd Evo 8 CS']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Evo 8 CS'] = cod_df['Qtd Evo 8 CS'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evo CS 24.45\n",
    "evo24cs_df = evo24cs_df.rename(columns= {'Qtd.componente (UMC)': 'Qtd Evo 24.25 CS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evo24cs_df = evo24cs_df.groupby('Nº componente')['Qtd Evo 24.25 CS'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(evo24cs_df[['Nº componente', 'Qtd Evo 24.25 CS']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Evo 24.25 CS'] = cod_df['Qtd Evo 24.25 CS'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joker 7 RT\n",
    "jok7_df = jok7_df.rename(columns= {'Qtd.componente (UMC)': 'Qtd Joker RT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jok7_df = jok7_df.groupby('Nº componente')['Qtd Joker RT'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(jok7_df[['Nº componente', 'Qtd Joker RT']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Joker RT'] = cod_df['Qtd Joker RT'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiniDrill\n",
    "mini_df = mini_df.rename(columns= {'Qtd.componente (UMC)': 'Qtd MiniDrill'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df = mini_df.groupby('Nº componente')['Qtd MiniDrill'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(mini_df[['Nº componente', 'Qtd MiniDrill']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd MiniDrill'] = cod_df['Qtd MiniDrill'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiniDrill SOLO\n",
    "mini_solo_df = mini_solo_df.rename(columns= {'Qtd.componente (UMC)': 'Qtd MiniDrill SOLO'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_solo_df = mini_solo_df.groupby('Nº componente')['Qtd MiniDrill SOLO'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(mini_solo_df[['Nº componente', 'Qtd MiniDrill SOLO']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd MiniDrill SOLO'] = cod_df['Qtd MiniDrill SOLO'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partner 2800 HT\n",
    "part_df = part_df.rename(columns= {'Qtd.componente (UMC)': 'Qtd Partner 2800 HT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_df = part_df.groupby('Nº componente')['Qtd Partner 2800 HT'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(part_df[['Nº componente', 'Qtd Partner 2800 HT']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Partner 2800 HT'] = cod_df['Qtd Partner 2800 HT'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiger MT\n",
    "tig_df = tig_df.rename(columns= {'Qtd.componente (UMC)': 'Qtd Tiger MT'})\n",
    "tig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tig_df = tig_df.groupby('Nº componente')['Qtd Tiger MT'].sum().reset_index().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(tig_df[['Nº componente', 'Qtd Tiger MT']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Tiger MT'] = cod_df['Qtd Tiger MT'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiniFlow\n",
    "mini_flow_df = mini_flow_df.rename(columns= {'Qtd.componente (UMC)': 'Qtd MiniFlow'})\n",
    "mini_flow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_flow_df = mini_flow_df.groupby('Nº componente')['Qtd MiniFlow'].sum().reset_index().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(mini_flow_df[['Nº componente', 'Qtd MiniFlow']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd MiniFlow'] = cod_df['Qtd MiniFlow'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insumos\n",
    "insumos_df = insumos_df.rename(columns= {'Qtd.componente (UMC)': 'Qtd Insumos'})\n",
    "insumos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insumos_df = insumos_df.groupby('Nº componente')['Qtd Insumos'].sum().reset_index().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(insumos_df[['Nº componente', 'Qtd Insumos']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Insumos'] = cod_df['Qtd Insumos'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ferramentas\n",
    "ferramentas_df = ferramentas_df.rename(columns= {'Qtd.componente (UMC)': 'Qtd Ferramentas'})\n",
    "ferramentas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferramentas_df = ferramentas_df.groupby('Nº componente')['Qtd Ferramentas'].sum().reset_index().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(ferramentas_df[['Nº componente', 'Qtd Ferramentas']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df['Qtd Ferramentas'] = cod_df['Qtd Ferramentas'].fillna(0)\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unidade de Medida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_df = cod_df.merge(concat_df[['Nº componente', 'Unidade de Medida']], left_on= 'PN', right_on= 'Nº componente', how= 'left')\n",
    "cod_df = cod_df.drop(columns= 'Nº componente')\n",
    "cod_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar para Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Programação Planejamento de Peças.xlsx'\n",
    "cod_df.to_excel(path, engine='openpyxl', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir o arquivo Excel para modificação\n",
    "book = load_workbook(path)\n",
    "sheet = book.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir estilo de preenchimento Células específicas\n",
    "fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')\n",
    "\n",
    "# Aplicar o estilo nas células\n",
    "for row in range(2, sheet.max_row + 1):\n",
    "    pn_cell = 'A' + str(row)  # ajuste conforme a coluna real de 'PN'\n",
    "    um_cell = 'BC' + str(row)  # ajuste conforme a coluna real de 'Unidade de Medida'\n",
    "    if sheet[pn_cell].value in ['00000180065', '00000200273']:\n",
    "        sheet[um_cell].fill = fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificar células para serem pintadas\n",
    "cells_to_fill = ['A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G1', 'H1', 'I1', 'J1', 'K1', 'L1', 'M1', 'N1', 'O1', 'P1', 'Q1', 'S1', 'T1', 'U1', 'V1', 'W1', 'X1', 'Y1', 'Z1', 'AA1', 'AB1', 'AC1', 'AD1', 'AE1', 'AF1', 'AG1', 'AH1', 'AI1', 'AJ1', 'AK1', 'AL1', 'AM1', 'AN1', 'AO1', 'AP1', 'AQ1', 'AR1', 'AS1', 'AT1', 'AU1', 'AV1', 'AW1', 'AX1', 'AY1', 'AZ1', 'BA1', 'BB1', 'BC1']\n",
    "\n",
    "# Estilo de preenchimento\n",
    "fill_2 = PatternFill(start_color='929294', end_color='929294', fill_type='solid')\n",
    "\n",
    "# Estilo da fonte \n",
    "font_white = Font(color='FFFFFF')\n",
    "\n",
    "# Aplicar o estilo na célula\n",
    "for cell in cells_to_fill:\n",
    "    sheet[cell].fill = fill_2\n",
    "    sheet[cell].font = font_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificar células para serem pintadas\n",
    "cells_to_fill_2 = ['R1', 'AD1', 'AE1', 'AF1', 'AG1', 'AH1', 'AM1', 'AN1', 'AO1', 'AP1', 'AQ1', 'AR1', 'AS1', 'AT1', 'AU1', 'AV1', 'AW1', 'AX1', 'AY1', 'AZ1', 'BA1', 'BB1', 'BC1', 'BD1', 'BE1', 'BF1']\n",
    "\n",
    "# Estilo de preenchimento\n",
    "fill_3 = PatternFill(start_color='A70623', end_color='A70623', fill_type='solid')\n",
    "\n",
    "# Estilo da fonte \n",
    "font_white = Font(color='FFFFFF')\n",
    "\n",
    "# Aplicar o estilo nas células especificadas\n",
    "for cell in cells_to_fill_2:\n",
    "    sheet[cell].fill = fill_3\n",
    "    sheet[cell].font = font_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar as alterações\n",
    "book.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histórico de Vendas ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas com informações não condinzentes com os dados de vendas\n",
    "doc2_df = doc2_df.drop(doc2_df[doc2_df['TpDocVend.'] != 'Z000'].index)\n",
    "doc2_df = doc2_df.drop(doc2_df[doc2_df['G~Ctg.NF'] != '1N'].index)\n",
    "doc2_df = doc2_df.drop(doc2_df[doc2_df['G~Estornado'] == 'X'].index)\n",
    "doc2_df = doc2_df.drop(doc2_df[doc2_df['Material'] =='00099000100'].index)\n",
    "doc2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2_df = doc2_df[['Material', 'Qtd.faturd', 'F~Dt.fatur.']]\n",
    "doc2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2_df.loc[:, 'Ano_Mes'] = doc2_df['F~Dt.fatur.'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2_df = doc2_df[['Material', 'Qtd.faturd', 'Ano_Mes']]\n",
    "doc2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2_df = doc2_df.groupby(['Material', 'Ano_Mes'])['Qtd.faturd'].sum().reset_index()\n",
    "doc2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2_df = doc2_df.pivot_table(index='Material', columns='Ano_Mes', values='Qtd.faturd', fill_value=0)\n",
    "doc2_df['Total'] = doc2_df.sum(axis=1)\n",
    "doc2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2_df.to_excel('C:\\\\Users\\\\scosta\\\\Desktop\\\\Bases Código Planejamento\\\\Histórico de Vendas.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
